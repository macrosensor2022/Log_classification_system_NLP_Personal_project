# Log Classification System (NLP)

A production-style, multi-stage log classification system that uses **Natural Language Processing** to automatically categorize system logs from multiple sources. The pipeline combines regex pattern matching, BERT-based embeddings, and an LLM for edge cases.

---

## ğŸ“¹ Demo Video

Watch a walkthrough of the project: setup, classification pipeline, API, and frontend.

<!-- Embed: replace with your hosted URL if you prefer; local path works when viewing in browser or VS Code -->
[**â–¶ Watch: Log Classification Demo**](docs/Log_classification_video.mp4)

<video src="docs/Log_classification_video.mp4" controls width="720" title="Log Classification Demo"></video>

*If the video does not render above, open [docs/Log_classification_video.mp4](docs/Log_classification_video.mp4) directly.*

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Project Structure](#-project-structure)
- [Prerequisites & Installation](#-prerequisites--installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Reference](#-api-reference)
- [Retraining the Model](#-retraining-the-model)
- [Documentation](#-documentation)
- [License & Author](#-license--author)

---

## âœ¨ Features

- **Multi-stage classification**: Regex â†’ BERT (embeddings) â†’ LLM (Groq), with routing by log source.
- **REST API**: Upload CSV or send JSON; get classified results and metrics.
- **Web UI**: Paste logs or upload CSV in the browser and view results in a table.
- **Metrics**: Per-label counts and request latency via `/metrics`.
- **Retraining**: Add new labeled examples and retrain the BERT classifier via API or CLI.
- **Sample data**: Ready-to-use sample logs for testing (see `resources/sample_logs.csv`).

---

## ğŸ— Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    Log Classification API                 â”‚
                    â”‚                     (FastAPI + Frontend)                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  Multi-Stage Pipeline (classify.py)        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                          â”‚                                           â”‚
         â–¼                                          â–¼                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  source ==       â”‚                    â”‚  Regex patterns      â”‚                    â”‚  BERT classifier     â”‚
â”‚  "LegacyCRM"?   â”‚â”€â”€ Yes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (processor_regex)   â”‚â”€â”€ No match â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (processor_bert)   â”‚
â”‚                 â”‚                    â”‚  User Action,        â”‚                    â”‚  SentenceTransformerâ”‚
â”‚                 â”‚â”€â”€ No â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  System Notif., etc. â”‚                    â”‚  + LogisticRegressionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                          â”‚
         â”‚ Yes                                      â”‚ Match
         â–¼                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM (Groq)     â”‚                    â”‚  Return label         â”‚
â”‚  processor_llm  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Workflow Error,â”‚
â”‚  Deprecation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for a more detailed breakdown.

---

## ğŸ“ Project Structure

```
Log_classification_system_NLP_Personal_project/
â”œâ”€â”€ server.py                 # FastAPI app: /classify, /classify-json, /metrics, /retrain
â”œâ”€â”€ main.py                   # Optional entry point
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ synthetic_logs.csv       # Original training dataset
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Log_classification_video.mp4   # Demo video
â”‚   â””â”€â”€ ARCHITECTURE.md                # Architecture and design notes
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html           # Web UI: paste logs or upload CSV
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ test.csv             # Minimal test CSV
â”‚   â”œâ”€â”€ sample_logs.csv      # Sample logs for testing
â”‚   â””â”€â”€ output.csv           # Last classification output (written by API)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ log_classification_model.pkl  # Trained BERT-era classifier (joblib)
â””â”€â”€ training/
    â”œâ”€â”€ training.ipynb       # Notebook: data load, clustering, regex, BERT training
    â”œâ”€â”€ classify.py           # Multi-stage pipeline + classify_batch / classify_csv
    â”œâ”€â”€ processor_regex.py    # Regex-based classifier
    â”œâ”€â”€ processor_bert.py     # BERT embeddings + Logistic Regression
    â”œâ”€â”€ processor_llm.py      # Groq LLM for LegacyCRM / edge cases
    â”œâ”€â”€ retrain.py            # Script to retrain from CSV (source, log_message, target_label)
    â””â”€â”€ .env                  # GROQ_API_KEY (not committed)
```

---

## ğŸ”§ Prerequisites & Installation

- **Python**: 3.9+ recommended.
- **Install dependencies**:

```bash
git clone <repository-url>
cd Log_classification_system_NLP_Personal_project
pip install -r requirements.txt
```

---

## âš™ Configuration

- **Groq API (LLM)**  
  Create `training/.env` with:

  ```
  GROQ_API_KEY=your_groq_api_key_here
  ```

  Get a key at [console.groq.com](https://console.groq.com).

- **Paths**  
  The server and training scripts assume they are run from the project root. Model path: `models/log_classification_model.pkl`.

---

## ğŸš€ Usage

### 1. Run the API and open the UI

```bash
uvicorn server:app --reload
```

- **Web UI**: [http://127.0.0.1:8000/](http://127.0.0.1:8000/) â€” paste logs or upload CSV, then view the results table.
- **API docs**: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

### 2. Classify from the command line (no server)

```bash
# Classify resources/test.csv and write resources/output.csv
cd training
python classify.py
```

### 3. Test with sample logs

- **Upload**: Use `resources/sample_logs.csv` in the web UI or via Postman (POST `/classify` with form-data key `file`).
- **Paste**: Copy the sample lines from the README or from `resources/sample_logs.csv` into the â€œPaste logsâ€ tab.

---

## ğŸ“¡ API Reference

| Method | Endpoint         | Description |
|--------|------------------|-------------|
| `GET`  | `/`              | Serve web UI (paste/upload, results table). |
| `POST` | `/classify`      | Upload CSV (`source`, `log_message`). Returns classified CSV. |
| `GET`  | `/classify`      | Download last classified CSV. |
| `POST` | `/classify-json` | JSON body `{ "logs": [ { "source", "log_message" } ] }`. Returns `{ "results": [ { "source", "log_message", "target_label" } ] }`. |
| `GET`  | `/metrics`       | Counts per label, total requests, average latency (ms). |
| `POST` | `/retrain`       | Upload CSV with `source`, `log_message`, `target_label` to merge into dataset and retrain BERT model. |

All responses use standard HTTP status codes. Errors return JSON with a `detail` field when applicable.

---

## ğŸ”„ Retraining the Model

- **Via API**: POST a CSV (columns `source`, `log_message`, `target_label`) to `/retrain` (form-data, key `file`). The server merges with `dataset/labeled_logs.csv` (or seeds from `synthetic_logs.csv` if needed) and retrains the BERT classifier.
- **Via CLI**:

  ```bash
  python -m training.retrain
  ```

  This uses `dataset/labeled_logs.csv` by default. To use another file:

  ```bash
  python -m training.retrain path/to/labeled.csv
  ```

---

## ğŸ“š Documentation

- **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)** â€” Pipeline design, components, and data flow.
- **Inline comments** â€” Key logic in `server.py`, `training/classify.py`, `training/processor_*.py`, `training/retrain.py`, and `static/index.html` is commented for maintainability.

---

## ğŸ“„ License & Author

This project is for **educational and portfolio use**.  
**Author**: Your Name  
**Last updated**: February 2026
